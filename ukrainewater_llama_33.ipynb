{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('Data/ukraine_water_reasons.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing reports: 100%|██████████| 500/500 [14:45<00:00,  1.77s/it]\n",
      "2024-12-23 17:00:55,359 - INFO - \n",
      "Processing complete!\n",
      "2024-12-23 17:00:55,359 - INFO - Successfully processed: 500 rows\n",
      "2024-12-23 17:00:55,360 - INFO - Errors: 0 rows\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import re\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Together API endpoint and key\n",
    "endpoint = 'https://api.together.xyz/inference'\n",
    "TOGETHER_API_KEY = os.getenv('TOGETHER_API_KEY')\n",
    "\n",
    "def prepare_prompt(text, code):\n",
    "    \"\"\"Prepare prompt for a specific code and text using Llama 3.3 instruct format.\"\"\"\n",
    "    codebook = {\n",
    "        'env_problems': \"Is the text about an environmental problem?\",\n",
    "        'pollution': \"Is the text about environmental pollution?\",\n",
    "        'treatment': \"Is the text about treatment plants or environmental technologies?\",\n",
    "        'climate': \"Is the text about climatic indicators?\",\n",
    "        'biomonitoring': \"Is the text about biological, biotic monitoring in water or in a river basin?\"\n",
    "    }\n",
    "    \n",
    "    return f\"\"\"[INST] Analyze this text and determine if it matches the given code definition. You must follow the exact format below and provide a clear Yes/No decision.\n",
    "\n",
    "TEXT TO ANALYZE:\n",
    "{text}\n",
    "\n",
    "CODE DEFINITION:\n",
    "{codebook[code]}\n",
    "\n",
    "Your response must contain these exact sections in this order:\n",
    "\n",
    "Key Elements:\n",
    "List 2-3 key elements from the text that are most relevant to the code definition.\n",
    "\n",
    "Analysis:\n",
    "Write 1-2 sentences explaining how these elements relate to the code definition.\n",
    "\n",
    "Decision:\n",
    "Write ONLY \"Yes\" or \"No\" - no other words or explanations here.\n",
    "\n",
    "Reason:\n",
    "Write exactly one clear sentence explaining your decision.\n",
    "\n",
    "IMPORTANT: \n",
    "- Keep responses direct and structured\n",
    "- Decision section must contain ONLY \"Yes\" or \"No\"\n",
    "- Each section must be clearly labeled\n",
    "- Reason must be one complete sentence\n",
    "[/INST]\"\"\"\n",
    "\n",
    "def clean_response_text(text):\n",
    "    \"\"\"Clean the response text by removing unwanted artifacts and formatting.\"\"\"\n",
    "    # Remove common LLM artifacts\n",
    "    artifacts = [\n",
    "        r'\\[/?INST\\]',          # [INST] tags\n",
    "        r'\\$\\\\boxed{.*?}\\$',    # LaTeX boxed answers\n",
    "        r'Step \\d+:.*?(?=\\n|$)', # Step-by-step instructions\n",
    "        r'The final answer is:.*?(?=\\n|$)',\n",
    "        r'<rewritten_response>.*?(?=\\n|$)',\n",
    "        r'becomes.*?(?=\\n|$)'\n",
    "    ]\n",
    "    \n",
    "    cleaned = text\n",
    "    for pattern in artifacts:\n",
    "        cleaned = re.sub(pattern, '', cleaned, flags=re.IGNORECASE | re.MULTILINE)\n",
    "    \n",
    "    # Split into lines and clean each line\n",
    "    cleaned_lines = []\n",
    "    for line in cleaned.split('\\n'):\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            cleaned_lines.append(line)\n",
    "            \n",
    "    return '\\n'.join(cleaned_lines)\n",
    "\n",
    "def extract_decision_and_reason(response_text):\n",
    "    \"\"\"Extract decision and reason from the structured response with enhanced reliability.\"\"\"\n",
    "    try:\n",
    "        if not response_text:\n",
    "            return \"Error\", \"Empty response received\"\n",
    "            \n",
    "        # Clean and normalize the text\n",
    "        response_text = response_text.replace('\\r', '\\n')\n",
    "        response_text = re.sub(r'\\n+', '\\n', response_text)\n",
    "        \n",
    "        # First try to find an explicit Yes/No decision\n",
    "        decision_pattern = r'(?:Decision:|.*?\\bfinal decision is\\b.*?:?)\\s*([Yy]es|[Nn]o)'\n",
    "        decision_match = re.search(decision_pattern, response_text)\n",
    "        \n",
    "        if not decision_match:\n",
    "            # Fallback: Look for yes/no anywhere in the text\n",
    "            yes_patterns = [r'\\b[Yy]es\\b', r'\\b[Yy]ep\\b', r'\\b[Yy]eah\\b']\n",
    "            no_patterns = [r'\\b[Nn]o\\b', r'\\b[Nn]ope\\b', r'\\b[Nn]ah\\b']\n",
    "            \n",
    "            has_yes = any(re.search(pattern, response_text) for pattern in yes_patterns)\n",
    "            has_no = any(re.search(pattern, response_text) for pattern in no_patterns)\n",
    "            \n",
    "            if has_yes and not has_no:\n",
    "                decision = \"Yes\"\n",
    "            elif has_no and not has_yes:\n",
    "                decision = \"No\"\n",
    "            else:\n",
    "                # If still no clear decision, analyze the text sentiment\n",
    "                negative_indicators = ['lacks', 'does not', 'doesn\\'t', 'absent', 'missing']\n",
    "                positive_indicators = ['contains', 'shows', 'demonstrates', 'indicates', 'presents']\n",
    "                \n",
    "                has_positive = any(indicator in response_text.lower() for indicator in positive_indicators)\n",
    "                has_negative = any(indicator in response_text.lower() for indicator in negative_indicators)\n",
    "                \n",
    "                if has_positive and not has_negative:\n",
    "                    decision = \"Yes\"\n",
    "                elif has_negative and not has_positive:\n",
    "                    decision = \"No\"\n",
    "                else:\n",
    "                    # Final fallback: analyze the overall response\n",
    "                    text_lower = response_text.lower()\n",
    "                    if any(word in text_lower for word in ['matches', 'aligns', 'relevant', 'consistent']):\n",
    "                        decision = \"Yes\"\n",
    "                    else:\n",
    "                        decision = \"No\"\n",
    "        else:\n",
    "            decision = decision_match.group(1).capitalize()\n",
    "\n",
    "        # Extract reason with multiple fallback strategies\n",
    "        reason = None\n",
    "        \n",
    "        # Strategy 1: Look for explicit Reason section\n",
    "        reason_match = re.search(r'Reason:(.+?)(?:\\n|$)', response_text, re.DOTALL)\n",
    "        if reason_match:\n",
    "            reason = reason_match.group(1).strip()\n",
    "            \n",
    "        # Strategy 2: Look for Analysis section\n",
    "        if not reason or len(reason) < 20:\n",
    "            analysis_match = re.search(r'Analysis:(.+?)(?:\\n(?:[A-Za-z]+:|$)|$)', response_text, re.DOTALL)\n",
    "            if analysis_match:\n",
    "                analysis_text = analysis_match.group(1).strip()\n",
    "                sentences = [s.strip() for s in analysis_text.split('.') if len(s.strip()) >= 20]\n",
    "                if sentences:\n",
    "                    reason = sentences[0]\n",
    "\n",
    "        # Strategy 3: Extract any sentence containing decision-related words\n",
    "        if not reason or len(reason) < 20:\n",
    "            sentences = [s.strip() + '.' for s in response_text.split('.') if len(s.strip()) >= 20]\n",
    "            decision_words = ['because', 'since', 'as', 'therefore', 'hence', 'indicates', 'shows']\n",
    "            for sentence in sentences:\n",
    "                if any(word in sentence.lower() for word in decision_words):\n",
    "                    reason = sentence\n",
    "                    break\n",
    "            \n",
    "            # If still no reason, take the longest sentence\n",
    "            if not reason and sentences:\n",
    "                reason = max(sentences, key=len)\n",
    "\n",
    "        # Final fallback\n",
    "        if not reason:\n",
    "            reason = f\"Based on the analysis of the provided text, the decision is {decision.lower()}.\"\n",
    "        \n",
    "        # Ensure reason ends with proper punctuation\n",
    "        if not reason.endswith(('.', '!', '?')):\n",
    "            reason += '.'\n",
    "            \n",
    "        return decision, reason\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error parsing response: {str(e)}\\nFull response: {response_text}\")\n",
    "        return \"Error\", str(e)\n",
    "\n",
    "def classify_text(text, code, retry_count=3):\n",
    "    \"\"\"Classify text with retries.\"\"\"\n",
    "    for attempt in range(retry_count):\n",
    "        try:\n",
    "            response = requests.post(\n",
    "                endpoint,\n",
    "                headers={\n",
    "                    \"Authorization\": f\"Bearer {TOGETHER_API_KEY}\",\n",
    "                    \"Content-Type\": \"application/json\"\n",
    "                },\n",
    "                json={\n",
    "                    \"model\": \"meta-llama/Llama-3.3-70B-Instruct-Turbo\",\n",
    "                    \"prompt\": prepare_prompt(text, code),\n",
    "                    \"max_tokens\": 400,\n",
    "                    \"temperature\": 0.1,\n",
    "                    \"top_p\": 0.7,\n",
    "                    \"top_k\": 40,\n",
    "                    \"repetition_penalty\": 1.1\n",
    "                }\n",
    "            )\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            response_json = response.json()\n",
    "            response_text = (\n",
    "                response_json.get('output', {}).get('choices', [{}])[0].get('text', '')\n",
    "                if isinstance(response_json.get('output'), dict)\n",
    "                else response_json.get('output', '')\n",
    "            )\n",
    "            \n",
    "            return extract_decision_and_reason(clean_response_text(response_text))\n",
    "            \n",
    "        except Exception as e:\n",
    "            if attempt == retry_count - 1:\n",
    "                return \"Error\", str(e)\n",
    "            time.sleep(2 ** attempt)\n",
    "    \n",
    "    return \"Error\", \"Maximum retries exceeded\"\n",
    "\n",
    "def process_single_report(args):\n",
    "    \"\"\"Process a single water quality report for parallel execution.\"\"\"\n",
    "    idx, row = args\n",
    "    try:\n",
    "        decision, reason = classify_text(row['text'], row['code_name'])\n",
    "        return {\n",
    "            'index': idx,\n",
    "            'prediction': decision,\n",
    "            'reasoning': reason,\n",
    "            'success': decision not in [\"Error\", None]\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing row {idx}: {str(e)}\")\n",
    "        return {\n",
    "            'index': idx,\n",
    "            'prediction': \"Error\",\n",
    "            'reasoning': str(e),\n",
    "            'success': False\n",
    "        }\n",
    "\n",
    "def process_water_reports(df, max_workers=10):\n",
    "    \"\"\"Process water quality reports in parallel with true concurrency.\"\"\"\n",
    "    df_processed = df.copy()\n",
    "    df_processed['model_prediction'] = None\n",
    "    df_processed['model_reasoning'] = None\n",
    "    \n",
    "    success_count = 0\n",
    "    error_count = 0\n",
    "    \n",
    "    # Create list of (index, row) tuples for parallel processing\n",
    "    tasks = list(df_processed.iterrows())\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = [executor.submit(process_single_report, task) for task in tasks]\n",
    "        \n",
    "        with tqdm(total=len(df_processed), desc=\"Processing reports\") as pbar:\n",
    "            for future in as_completed(futures):\n",
    "                result = future.result()\n",
    "                df_processed.at[result['index'], 'model_prediction'] = result['prediction']\n",
    "                df_processed.at[result['index'], 'model_reasoning'] = result['reasoning']\n",
    "                \n",
    "                if result['success']:\n",
    "                    success_count += 1\n",
    "                else:\n",
    "                    error_count += 1\n",
    "                    \n",
    "                pbar.update(1)\n",
    "    \n",
    "    logging.info(f\"\\nProcessing complete!\")\n",
    "    logging.info(f\"Successfully processed: {success_count} rows\")\n",
    "    logging.info(f\"Errors: {error_count} rows\")\n",
    "    \n",
    "    return df_processed\n",
    "df_results = process_water_reports(df, max_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  text      code_name  \\\n",
      "56   In the Southern Bug basin the main part of the...      pollution   \n",
      "177  It is worth of mentioning the low level of tre...      treatment   \n",
      "215  This method allows extracting only a part of p...   env_problems   \n",
      "226  Phosphorus belongs to the elements which hardl...      pollution   \n",
      "276  Compared with vodocanals discharging 488 tons ...      pollution   \n",
      "354  Southern Bug basin is located on the territory...  biomonitoring   \n",
      "\n",
      "    model_prediction                       model_reasoning  \n",
      "56             Error  Could not find clear Yes/No decision  \n",
      "177            Error  Could not find clear Yes/No decision  \n",
      "215            Error  Could not find clear Yes/No decision  \n",
      "226            Error  Could not find clear Yes/No decision  \n",
      "276            Error  Could not find clear Yes/No decision  \n",
      "354            Error  Could not find clear Yes/No decision  \n"
     ]
    }
   ],
   "source": [
    "# Display all rows where there was an error\n",
    "error_rows = df_results[df_results['model_prediction'] == 'Error']\n",
    "print(error_rows[['text', 'code_name', 'model_prediction', 'model_reasoning']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_results.to_csv('results_csvs/water_quality_llama_33.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>code_id</th>\n",
       "      <th>code_name</th>\n",
       "      <th>text</th>\n",
       "      <th>original_code</th>\n",
       "      <th>replicated_code</th>\n",
       "      <th>model_code</th>\n",
       "      <th>reason</th>\n",
       "      <th>model_prediction</th>\n",
       "      <th>model_reasoning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>env_problems</td>\n",
       "      <td>Autumn period especially its second half is ch...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>The text is not about an environmental problem...</td>\n",
       "      <td>No</td>\n",
       "      <td>The text describes typical seasonal weather co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>pollution</td>\n",
       "      <td>Autumn period especially its second half is ch...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>The text is not about environmental pollution,...</td>\n",
       "      <td>No</td>\n",
       "      <td>The text describes natural weather conditions ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>treatment</td>\n",
       "      <td>Autumn period especially its second half is ch...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>The text is not about treatment plants or envi...</td>\n",
       "      <td>No</td>\n",
       "      <td>The text does not discuss treatment plants or ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>climate</td>\n",
       "      <td>Autumn period especially its second half is ch...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>The text is not about climatic indicators, but...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>The text specifically mentions various weather...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>biomonitoring</td>\n",
       "      <td>Autumn period especially its second half is ch...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>The text is not about biological or biotic mon...</td>\n",
       "      <td>No</td>\n",
       "      <td>The text does not discuss biological or biotic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>env_problems</td>\n",
       "      <td>Mineralization of organic phosphorus in bottom...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>The text discusses an environmental problem re...</td>\n",
       "      <td>No</td>\n",
       "      <td>The text does not explicitly describe or imply...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>pollution</td>\n",
       "      <td>Mineralization of organic phosphorus in bottom...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>The text discusses the mineralization of organ...</td>\n",
       "      <td>No</td>\n",
       "      <td>The text discusses a natural process of minera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "      <td>treatment</td>\n",
       "      <td>Mineralization of organic phosphorus in bottom...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>The text is not about treatment plants or envi...</td>\n",
       "      <td>No</td>\n",
       "      <td>The text does not explicitly discuss treatment...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>99</td>\n",
       "      <td>3</td>\n",
       "      <td>climate</td>\n",
       "      <td>Mineralization of organic phosphorus in bottom...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>The text is not about climatic indicators, but...</td>\n",
       "      <td>No</td>\n",
       "      <td>The text primarily discusses a biochemical pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>99</td>\n",
       "      <td>4</td>\n",
       "      <td>biomonitoring</td>\n",
       "      <td>Mineralization of organic phosphorus in bottom...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>The text is not about biological or biotic mon...</td>\n",
       "      <td>No</td>\n",
       "      <td>The text does not explicitly discuss biologica...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     text_id  code_id      code_name  \\\n",
       "0          0        0   env_problems   \n",
       "1          0        1      pollution   \n",
       "2          0        2      treatment   \n",
       "3          0        3        climate   \n",
       "4          0        4  biomonitoring   \n",
       "..       ...      ...            ...   \n",
       "495       99        0   env_problems   \n",
       "496       99        1      pollution   \n",
       "497       99        2      treatment   \n",
       "498       99        3        climate   \n",
       "499       99        4  biomonitoring   \n",
       "\n",
       "                                                  text original_code  \\\n",
       "0    Autumn period especially its second half is ch...            No   \n",
       "1    Autumn period especially its second half is ch...            No   \n",
       "2    Autumn period especially its second half is ch...            No   \n",
       "3    Autumn period especially its second half is ch...           Yes   \n",
       "4    Autumn period especially its second half is ch...            No   \n",
       "..                                                 ...           ...   \n",
       "495  Mineralization of organic phosphorus in bottom...           Yes   \n",
       "496  Mineralization of organic phosphorus in bottom...            No   \n",
       "497  Mineralization of organic phosphorus in bottom...            No   \n",
       "498  Mineralization of organic phosphorus in bottom...            No   \n",
       "499  Mineralization of organic phosphorus in bottom...           Yes   \n",
       "\n",
       "    replicated_code model_code  \\\n",
       "0                No         No   \n",
       "1                No         No   \n",
       "2                No         No   \n",
       "3               Yes         No   \n",
       "4                No         No   \n",
       "..              ...        ...   \n",
       "495              No        Yes   \n",
       "496              No        Yes   \n",
       "497              No         No   \n",
       "498              No         No   \n",
       "499             Yes         No   \n",
       "\n",
       "                                                reason model_prediction  \\\n",
       "0    The text is not about an environmental problem...               No   \n",
       "1    The text is not about environmental pollution,...               No   \n",
       "2    The text is not about treatment plants or envi...               No   \n",
       "3    The text is not about climatic indicators, but...              Yes   \n",
       "4    The text is not about biological or biotic mon...               No   \n",
       "..                                                 ...              ...   \n",
       "495  The text discusses an environmental problem re...               No   \n",
       "496  The text discusses the mineralization of organ...               No   \n",
       "497  The text is not about treatment plants or envi...               No   \n",
       "498  The text is not about climatic indicators, but...               No   \n",
       "499  The text is not about biological or biotic mon...               No   \n",
       "\n",
       "                                       model_reasoning  \n",
       "0    The text describes typical seasonal weather co...  \n",
       "1    The text describes natural weather conditions ...  \n",
       "2    The text does not discuss treatment plants or ...  \n",
       "3    The text specifically mentions various weather...  \n",
       "4    The text does not discuss biological or biotic...  \n",
       "..                                                 ...  \n",
       "495  The text does not explicitly describe or imply...  \n",
       "496  The text discusses a natural process of minera...  \n",
       "497  The text does not explicitly discuss treatment...  \n",
       "498  The text primarily discusses a biochemical pro...  \n",
       "499  The text does not explicitly discuss biologica...  \n",
       "\n",
       "[500 rows x 10 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_prediction\n",
       "No       302\n",
       "Yes      197\n",
       "Error      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results['model_prediction'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     text_id  code_id     code_name  \\\n",
      "200       40        0  env_problems   \n",
      "\n",
      "                                                  text original_code  \\\n",
      "200  The average amount of precipitation in the low...            No   \n",
      "\n",
      "    replicated_code model_code  \\\n",
      "200              No         No   \n",
      "\n",
      "                                                reason model_prediction  \\\n",
      "200  The text is providing information about precip...            Error   \n",
      "\n",
      "                          model_reasoning  \n",
      "200  Could not find clear Yes/No decision  \n"
     ]
    }
   ],
   "source": [
    "print(df_results[df_results['model_prediction'] == 'Error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity Analysis Summary:\n",
      "====================================================================================================\n",
      "                       Comparison  Accuracy  Kappa Score  Matching Cases  Total Cases  Match Percentage\n",
      "      Original Model vs New Model     0.904        0.761             452          500              90.4\n",
      "  Original Code vs Original Model     0.856        0.631             428          500              85.6\n",
      "       Original Code vs New Model     0.864        0.663             432          500              86.4\n",
      "Replicated Code vs Original Model     0.738        0.251             369          500              73.8\n",
      "     Replicated Code vs New Model     0.758        0.342             379          500              75.8\n",
      "\n",
      "Detailed Analysis:\n",
      "====================================================================================================\n",
      "\n",
      "Confusion Matrix for Original Model vs New Model:\n",
      "Categories: ['No', 'Yes']\n",
      "[[337  31]\n",
      " [ 17 115]]\n",
      "\n",
      "Confusion Matrix for Original Code vs Original Model:\n",
      "Categories: ['No', 'Yes']\n",
      "[[331  35]\n",
      " [ 37  97]]\n",
      "\n",
      "Confusion Matrix for Original Code vs New Model:\n",
      "Categories: ['No', 'Yes']\n",
      "[[326  40]\n",
      " [ 28 106]]\n",
      "\n",
      "Confusion Matrix for Replicated Code vs Original Model:\n",
      "Categories: ['No', 'Yes']\n",
      "[[323  86]\n",
      " [ 45  46]]\n",
      "\n",
      "Confusion Matrix for Replicated Code vs New Model:\n",
      "Categories: ['No', 'Yes']\n",
      "[[321  88]\n",
      " [ 33  58]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, confusion_matrix\n",
    "\n",
    "def perform_similarity_analysis(df):\n",
    "    # Clean the data by filling NaN values\n",
    "    df_results = df.fillna('No')  # or whatever default value makes sense\n",
    "    \n",
    "    # Make sure all values are strings\n",
    "    columns_to_convert = ['original_code', 'replicated_code', 'model_code', 'model_prediction']\n",
    "    for col in columns_to_convert:\n",
    "        df_results[col] = df_results[col].astype(str)\n",
    "    \n",
    "    # Define comparisons to analyze\n",
    "    comparisons = [\n",
    "        ('model_code', 'model_prediction', 'Original Model vs New Model'),\n",
    "        ('original_code', 'model_code', 'Original Code vs Original Model'),\n",
    "        ('original_code', 'model_prediction', 'Original Code vs New Model'),\n",
    "        ('replicated_code', 'model_code', 'Replicated Code vs Original Model'),\n",
    "        ('replicated_code', 'model_prediction', 'Replicated Code vs New Model')\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for col1, col2, name in comparisons:\n",
    "        # Skip if column doesn't exist\n",
    "        if col1 not in df_results.columns or col2 not in df_results.columns:\n",
    "            print(f\"Warning: Columns {col1} or {col2} not found in DataFrame\")\n",
    "            continue\n",
    "            \n",
    "        accuracy = accuracy_score(df_results[col1], df_results[col2])\n",
    "        kappa = cohen_kappa_score(df_results[col1], df_results[col2])\n",
    "        matching_cases = (df_results[col1] == df_results[col2]).sum()\n",
    "        total_cases = len(df_results)\n",
    "        match_percentage = (matching_cases / total_cases) * 100\n",
    "        \n",
    "        results.append({\n",
    "            'Comparison': name,\n",
    "            'Accuracy': round(accuracy, 3),\n",
    "            'Kappa Score': round(kappa, 3),\n",
    "            'Matching Cases': matching_cases,\n",
    "            'Total Cases': total_cases,\n",
    "            'Match Percentage': round(match_percentage, 2)\n",
    "        })\n",
    "    \n",
    "    # Create results DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\nSimilarity Analysis Summary:\")\n",
    "    print(\"=\" * 100)\n",
    "    print(results_df.to_string(index=False))\n",
    "    \n",
    "    # Print detailed analysis\n",
    "    print(\"\\nDetailed Analysis:\")\n",
    "    print(\"=\" * 100)\n",
    "    \n",
    "    for col1, col2, name in comparisons:\n",
    "        if col1 not in df_results.columns or col2 not in df_results.columns:\n",
    "            continue\n",
    "            \n",
    "        matrix = confusion_matrix(df_results[col1], df_results[col2])\n",
    "        print(f\"\\nConfusion Matrix for {name}:\")\n",
    "        categories = sorted(df_results[col1].unique().tolist())\n",
    "        print(f\"Categories: {categories}\")\n",
    "        print(matrix)\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "# Run the analysis\n",
    "results_df = perform_similarity_analysis(df_results)\n",
    "# save_analysis_results(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Internal Consistency Analysis:\n",
      "Percentage of fully consistent texts: 25.0%\n",
      "Average unique predictions per text: 1.75\n",
      "Total number of texts analyzed: 100\n",
      "\n",
      "Code Pattern Analysis:\n",
      "Distribution of Yes/No predictions by code ID:\n",
      "         positive_rate  total_assignments\n",
      "code_id                                  \n",
      "0                 0.47                100\n",
      "1                 0.48                100\n",
      "2                 0.18                100\n",
      "3                 0.19                100\n",
      "4                 0.14                100\n",
      "\n",
      "Reasoning Pattern Analysis:\n",
      "Average reasoning length: 192.3 characters\n",
      "Number of unique reasoning patterns: 499\n",
      "\n",
      "Most common reasoning phrases:\n",
      "- in.... (13 occurrences)\n",
      "- defined by the code.... (2 occurrences)\n",
      "- ins.... (2 occurrences)\n",
      "- pects.... (2 occurrences)\n",
      "- snow cover and frost penetration depths.... (2 occurrences)\n",
      "\n",
      "Code Dependencies Analysis:\n",
      "No significant dependencies found between codes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import re\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "class ModelOutputAnalyzer:\n",
    "    def __init__(self, df_results):\n",
    "        \"\"\"\n",
    "        Initialize with the df_results DataFrame containing model outputs\n",
    "        Required columns: text_id, code_id, model_prediction, model_reasoning\n",
    "        \"\"\"\n",
    "        self.df = df_results.copy()\n",
    "        self._validate_data()\n",
    "        \n",
    "    def _validate_data(self):\n",
    "        required_cols = ['text_id', 'code_id', 'model_prediction', 'model_reasoning']\n",
    "        missing_cols = [col for col in required_cols if col not in self.df.columns]\n",
    "        if missing_cols:\n",
    "            raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "    \n",
    "    def analyze_internal_consistency(self):\n",
    "        \"\"\"Analyze how consistent the model is across different codes for the same text\"\"\"\n",
    "        consistency = self.df.groupby('text_id').agg({\n",
    "            'model_prediction': lambda x: len(set(x)),  # Unique predictions per text\n",
    "            'code_id': 'count'  # Total codes per text\n",
    "        })\n",
    "        \n",
    "        results = {\n",
    "            'fully_consistent_texts': (consistency['model_prediction'] == 1).mean(),\n",
    "            'avg_unique_predictions': consistency['model_prediction'].mean(),\n",
    "            'total_texts': len(consistency)\n",
    "        }\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def analyze_code_patterns(self):\n",
    "        \"\"\"Analyze patterns in how different codes are assigned\"\"\"\n",
    "        code_stats = self.df.groupby('code_id').agg({\n",
    "            'model_prediction': lambda x: (x == 'Yes').mean(),\n",
    "            'text_id': 'count'\n",
    "        }).round(3)\n",
    "        \n",
    "        code_stats.columns = ['positive_rate', 'total_assignments']\n",
    "        return code_stats\n",
    "    \n",
    "    def analyze_reasoning_patterns(self):\n",
    "        \"\"\"Analyze patterns in the reasoning provided\"\"\"\n",
    "        # Extract key phrases (words following common indicators)\n",
    "        indicators = ['because', 'as', 'since', 'due to', 'indicates', 'shows']\n",
    "        \n",
    "        def extract_key_phrase(text):\n",
    "            text = str(text).lower()\n",
    "            for indicator in indicators:\n",
    "                if indicator in text:\n",
    "                    idx = text.index(indicator) + len(indicator)\n",
    "                    return text[idx:idx + 100].strip()  # Get 100 chars after indicator\n",
    "            return None\n",
    "            \n",
    "        reasoning_analysis = {\n",
    "            'avg_length': self.df['model_reasoning'].str.len().mean(),\n",
    "            'unique_patterns': len(self.df['model_reasoning'].unique()),\n",
    "            'common_phrases': Counter([\n",
    "                phrase for phrase in self.df['model_reasoning'].apply(extract_key_phrase)\n",
    "                if phrase is not None\n",
    "            ]).most_common(5)\n",
    "        }\n",
    "        \n",
    "        return reasoning_analysis\n",
    "    \n",
    "    def analyze_prediction_dependencies(self):\n",
    "        \"\"\"Analyze if predictions for different codes seem dependent\"\"\"\n",
    "        code_pairs = []\n",
    "        unique_codes = self.df['code_id'].unique()\n",
    "        \n",
    "        for i in range(len(unique_codes)):\n",
    "            for j in range(i + 1, len(unique_codes)):\n",
    "                code1, code2 = unique_codes[i], unique_codes[j]\n",
    "                \n",
    "                # Get predictions for texts that have both codes\n",
    "                texts_with_both = set(self.df[self.df['code_id'] == code1]['text_id']) & \\\n",
    "                                set(self.df[self.df['code_id'] == code2]['text_id'])\n",
    "                \n",
    "                if texts_with_both:\n",
    "                    pred1 = self.df[\n",
    "                        (self.df['code_id'] == code1) & \n",
    "                        (self.df['text_id'].isin(texts_with_both))\n",
    "                    ]['model_prediction']\n",
    "                    \n",
    "                    pred2 = self.df[\n",
    "                        (self.df['code_id'] == code2) & \n",
    "                        (self.df['text_id'].isin(texts_with_both))\n",
    "                    ]['model_prediction']\n",
    "                    \n",
    "                    # Create contingency table\n",
    "                    cont_table = pd.crosstab(pred1, pred2)\n",
    "                    \n",
    "                    # Calculate chi-square test\n",
    "                    try:\n",
    "                        _, p_value, _, _ = chi2_contingency(cont_table)\n",
    "                        code_pairs.append({\n",
    "                            'code_id_1': code1,\n",
    "                            'code_id_2': code2,\n",
    "                            'p_value': p_value,\n",
    "                            'n_texts': len(texts_with_both)\n",
    "                        })\n",
    "                    except:\n",
    "                        continue\n",
    "                        \n",
    "        return pd.DataFrame(code_pairs) if code_pairs else pd.DataFrame()\n",
    "    \n",
    "    def get_full_analysis(self):\n",
    "        \"\"\"Run all analyses and return comprehensive results\"\"\"\n",
    "        return {\n",
    "            'consistency': self.analyze_internal_consistency(),\n",
    "            'code_patterns': self.analyze_code_patterns(),\n",
    "            'reasoning_patterns': self.analyze_reasoning_patterns(),\n",
    "            'dependencies': self.analyze_prediction_dependencies()\n",
    "        }\n",
    "\n",
    "# Example usage with df_results:\n",
    "analyzer = ModelOutputAnalyzer(df_results)\n",
    "analysis_results = analyzer.get_full_analysis()\n",
    "\n",
    "print(\"\\nInternal Consistency Analysis:\")\n",
    "print(f\"Percentage of fully consistent texts: {analysis_results['consistency']['fully_consistent_texts']:.1%}\")\n",
    "print(f\"Average unique predictions per text: {analysis_results['consistency']['avg_unique_predictions']:.2f}\")\n",
    "print(f\"Total number of texts analyzed: {analysis_results['consistency']['total_texts']}\")\n",
    "\n",
    "print(\"\\nCode Pattern Analysis:\")\n",
    "print(\"Distribution of Yes/No predictions by code ID:\")\n",
    "print(analysis_results['code_patterns'])\n",
    "\n",
    "print(\"\\nReasoning Pattern Analysis:\")\n",
    "print(f\"Average reasoning length: {analysis_results['reasoning_patterns']['avg_length']:.1f} characters\")\n",
    "print(f\"Number of unique reasoning patterns: {analysis_results['reasoning_patterns']['unique_patterns']}\")\n",
    "print(\"\\nMost common reasoning phrases:\")\n",
    "for phrase, count in analysis_results['reasoning_patterns']['common_phrases']:\n",
    "    print(f\"- {phrase[:50]}... ({count} occurrences)\")\n",
    "\n",
    "print(\"\\nCode Dependencies Analysis:\")\n",
    "dependencies = analysis_results['dependencies']\n",
    "if isinstance(dependencies, pd.DataFrame) and not dependencies.empty:\n",
    "    significant_deps = dependencies[dependencies['p_value'] < 0.05]\n",
    "    print(f\"Found {len(significant_deps)} significant dependencies between codes\")\n",
    "    if len(significant_deps) > 0:\n",
    "        print(\"\\nMost significant dependencies:\")\n",
    "        print(significant_deps.sort_values('p_value').head())\n",
    "else:\n",
    "    print(\"No significant dependencies found between codes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_results.to_csv('results_csvs/water_quality_prompt_final.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
